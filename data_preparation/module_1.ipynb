{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHQGz4-gs_DG"
      },
      "source": [
        "dataset processing for component1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVB4Xqluu_HW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def merge_review_data():\n",
        "    review_detail_df = pd.read_csv('game_review.csv')\n",
        "    print(f\"game_review.csv loaded successfully, total reviews: {len(review_detail_df)}\")\n",
        "\n",
        "    review_stats_df = pd.read_csv('game_review_800.csv')\n",
        "    print(f\"game_review_800.csv loaded successfully, total games: {len(review_stats_df)}\")\n",
        "    matched_games_df = pd.read_csv('games.csv')\n",
        "    print(f\"games.csv loaded successfully, total games: {len(matched_games_df)}\")\n",
        "\n",
        "    print(\"\\nFiltering reviews based on game_review_800.csv...\")\n",
        "\n",
        "    target_app_ids = set(review_stats_df['app_id'].tolist())\n",
        "\n",
        "    review_detail_df_filtered = review_detail_df[review_detail_df['app_id'].isin(target_app_ids)].copy()\n",
        "    print(f\"game amount after filtering: {len(target_app_ids)}\")\n",
        "    print(f\"game review amount after filtering: {len(review_detail_df_filtered)} \")\n",
        "\n",
        "    review_detail_df_filtered['review_text'] = review_detail_df_filtered['review_text'].apply(clean_text)\n",
        "\n",
        "    grouped_reviews = review_detail_df_filtered.groupby('app_id')['review_text'].apply(\n",
        "        lambda x: ' ||| '.join(x.tolist())\n",
        "    ).reset_index()\n",
        "    grouped_reviews.columns = ['app_id', 'combined_reviews']\n",
        "\n",
        "    merged_df = pd.merge(\n",
        "        review_stats_df,\n",
        "        grouped_reviews,\n",
        "        on='app_id',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    merged_df = pd.merge(\n",
        "        merged_df,\n",
        "        matched_games_df[['app_id', 'title']],\n",
        "        on='app_id',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    columns = ['app_id', 'title'] + [col for col in merged_df.columns if col not in ['app_id', 'title']]\n",
        "    merged_df = merged_df[columns]\n",
        "\n",
        "    sentiment_df = merged_df[['app_id', 'title', 'combined_reviews', 'recommendation_rate', 'total_reviews']].copy()\n",
        "    sentiment_df.rename(columns={'combined_reviews': 'review_text'}, inplace=True)\n",
        "\n",
        "    sentiment_detailed_df = review_detail_df_filtered.copy()\n",
        "\n",
        "    title_mapping = matched_games_df.set_index('app_id')['title'].to_dict()\n",
        "    sentiment_detailed_df['title'] = sentiment_detailed_df['app_id'].map(title_mapping)\n",
        "\n",
        "    stats_mapping = review_stats_df.set_index('app_id')\n",
        "    for col in ['total_reviews', 'recommendation_rate']:\n",
        "        sentiment_detailed_df[col] = sentiment_detailed_df['app_id'].map(\n",
        "            stats_mapping[col] if col in stats_mapping.columns else pd.Series()\n",
        "        )\n",
        "\n",
        "    sentiment_detailed_cols = ['app_id', 'title', 'review_text', 'recommendation',\n",
        "                               'hours', 'date_posted', 'username', 'total_reviews',\n",
        "                               'recommendation_rate']\n",
        "    sentiment_detailed_df = sentiment_detailed_df[sentiment_detailed_cols]\n",
        "\n",
        "    merged_df.to_csv('merged_game_reviews.csv', index=False, encoding='utf-8-sig')\n",
        "    print(f\"merge data has been saved to merged_game_reviews.csv, total line: {len(merged_df)} \")\n",
        "\n",
        "    sentiment_df.to_csv('sentiment_analysis_combined.csv', index=False, encoding='utf-8-sig')\n",
        "    print(f\"overall sentiment analysis data has been saved to sentiment_analysis_combined.csv, total line {len(sentiment_df)} \")\n",
        "\n",
        "    sentiment_detailed_df.to_csv('sentiment_analysis_detailed.csv', index=False, encoding='utf-8-sig')\n",
        "    print(f\"individual sentiment analysis data has been saved to sentiment_analysis_detailed.csv, total line {len(sentiment_detailed_df)} rows\")\n",
        "\n",
        "    split_reviews_df = sentiment_detailed_df[['app_id', 'title', 'review_text', 'recommendation']].copy()\n",
        "\n",
        "    split_reviews_df['sentiment_label'] = split_reviews_df['recommendation'].apply(\n",
        "        lambda x: 1 if x == 'Recommended' else 0\n",
        "    )\n",
        "\n",
        "    split_reviews_df.to_csv('split_reviews_for_analysis.csv', index=False, encoding='utf-8-sig')\n",
        "    print(f\"The split comment version has been saved to split_reviews_for_analysis.csv, total {len(split_reviews_df)} lines.\")\n",
        "\n",
        "    print(\"\\n=== Data Statistics ===\")\n",
        "    print(f\"Number of target games (from game_review_800.csv): {len(review_stats_df)}\")\n",
        "    print(f\"Total number of reviews after filtering: {len(review_detail_df_filtered)}\")\n",
        "    if len(review_stats_df) > 0:\n",
        "        print(f\"Average number of reviews per target game: {len(review_detail_df_filtered) / len(review_stats_df):.1f}\")\n",
        "    else:\n",
        "        print(\"Average number of reviews per target game: 0\")\n",
        "\n",
        "    print(\"\\n=== Sample Data (first 3 rows) ===\")\n",
        "    print(merged_df[['app_id', 'title', 'total_reviews', 'recommendation_rate']].head(3))\n",
        "\n",
        "    print(\"\\n=== Review Sample ===\")\n",
        "    if len(sentiment_detailed_df) > 0:\n",
        "        sample_review = sentiment_detailed_df.iloc[0]['review_text']\n",
        "        print(f\"First review (first 200 characters): {sample_review[:200]}...\")\n",
        "    else:\n",
        "        print(\"No review data\")\n",
        "\n",
        "    return merged_df, sentiment_df, sentiment_detailed_df\n",
        "\n",
        "def analyze_review_lengths(df):\n",
        "    if len(df) == 0:\n",
        "        print(\"No data to analyze\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n=== Review Length Analysis ===\")\n",
        "\n",
        "    df['review_length'] = df['review_text'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "    print(f\"Average review length (in words): {df['review_length'].mean():.1f}\")\n",
        "    print(f\"Shortest review length: {df['review_length'].min()}\")\n",
        "    print(f\"Longest review length: {df['review_length'].max()}\")\n",
        "    print(f\"Median review length: {df['review_length'].median()}\")\n",
        "\n",
        "    length_bins = [0, 10, 50, 100, 200, 500, float('inf')]\n",
        "    length_labels = ['0-10', '11-50', '51-100', '101-200', '201-500', '500+']\n",
        "\n",
        "    df['length_category'] = pd.cut(df['review_length'], bins=length_bins, labels=length_labels)\n",
        "    length_dist = df['length_category'].value_counts().sort_index()\n",
        "\n",
        "    print(\"\\nReview length distribution:\")\n",
        "    for category, count in length_dist.items():\n",
        "        percentage = (count / len(df)) * 100\n",
        "        print(f\" {category} words: {count} reviews ({percentage:.1f}%)\")\n",
        "\n",
        "    print(\"\\n=== Recommendation ===\")\n",
        "    avg_length = df['review_length'].mean()\n",
        "    if avg_length > 100:\n",
        "        print(\"Reviews are long. It is recommended to use the split version (split_reviews_for_analysis.csv) for sentiment analysis.\")\n",
        "        print(\"Analyzing each review individually can yield more accurate sentiment tendencies.\")\n",
        "    else:\n",
        "        print(\"Review length is moderate. You can use either the combined or split version for analysis.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        required_files = ['game_review.csv', 'game_review_800.csv', 'games.csv']\n",
        "        missing_files = [f for f in required_files if not Path(f).exists()]\n",
        "\n",
        "        if missing_files:\n",
        "            print(f\"Error: Missing files: {', '.join(missing_files)}\")\n",
        "            print(\"Please ensure all files are in the current directory.\")\n",
        "        else:\n",
        "            merged_df, sentiment_df, detailed_df = merge_review_data()\n",
        "            analyze_review_lengths(detailed_df)\n",
        "\n",
        "            print(\"\\n=== File Descriptions ===\")\n",
        "            print(\"1. merged_game_reviews.csv - Complete merged data (statistics and reviews for target games only)\")\n",
        "            print(\"2. sentiment_analysis_combined.csv - Overall sentiment analysis data (reviews combined per game)\")\n",
        "            print(\"3. sentiment_analysis_detailed.csv - Detailed sentiment analysis data (each review separate)\")\n",
        "            print(\"4. split_reviews_for_analysis.csv - Split review version (target game reviews only, best for sentiment analysis)\")\n",
        "\n",
        "            print(\"\\nProcessing complete!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during processing: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuCbifxovAzp"
      },
      "source": [
        "code for module 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ub9MZ4T6vEwP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "try:\n",
        "    nltk.download('vader_lexicon', quiet=True)\n",
        "except:\n",
        "    print(\"Downloading VADER sentiment lexicon...\")\n",
        "    nltk.download('vader_lexicon')\n",
        "\n",
        "def load_and_prepare_data():\n",
        "    print(\"Loading data...\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv('split_reviews_for_analysis.csv')\n",
        "        print(f\"Successfully loaded {len(df)} reviews\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: split_reviews_for_analysis.csv file not found\")\n",
        "        print(\"Please run the previous code to generate this file\")\n",
        "        return None\n",
        "\n",
        "    required_cols = ['app_id', 'title', 'review_text', 'recommendation', 'sentiment_label']\n",
        "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "    if missing_cols:\n",
        "        print(f\"Error: Missing required columns: {missing_cols}\")\n",
        "        return None\n",
        "\n",
        "    print(\"Cleaning review text...\")\n",
        "    df['review_text'] = df['review_text'].astype(str).apply(\n",
        "        lambda x: re.sub(r'\\s+', ' ', x).strip()\n",
        "    )\n",
        "\n",
        "    df = df[df['review_text'].str.len() > 10]\n",
        "    print(f\"{len(df)} valid reviews retained after cleaning\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def analyze_sentiment_with_vader(text, analyzer):\n",
        "    sentiment_scores = analyzer.polarity_scores(text)\n",
        "    compound_score = sentiment_scores['compound']\n",
        "    normalized_score = (compound_score + 1) / 2\n",
        "\n",
        "    if compound_score >= 0.05:\n",
        "        sentiment_category = 'positive'\n",
        "    elif compound_score <= -0.05:\n",
        "        sentiment_category = 'negative'\n",
        "    else:\n",
        "        sentiment_category = 'neutral'\n",
        "\n",
        "    return {\n",
        "        'compound': compound_score,\n",
        "        'normalized': normalized_score,\n",
        "        'category': sentiment_category,\n",
        "        'positive': sentiment_scores['pos'],\n",
        "        'negative': sentiment_scores['neg'],\n",
        "        'neutral': sentiment_scores['neu']\n",
        "    }\n",
        "\n",
        "def apply_recommendation_priority(row, sentiment_result):\n",
        "    if row['sentiment_label'] == 1 and sentiment_result['category'] in ['negative', 'neutral']:\n",
        "        adjusted_score = max(sentiment_result['normalized'], 0.7)\n",
        "        adjusted_category = 'positive'\n",
        "\n",
        "        return {\n",
        "            'original_score': sentiment_result['normalized'],\n",
        "            'adjusted_score': adjusted_score,\n",
        "            'original_category': sentiment_result['category'],\n",
        "            'adjusted_category': adjusted_category,\n",
        "            'was_adjusted': True\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            'original_score': sentiment_result['normalized'],\n",
        "            'adjusted_score': sentiment_result['normalized'],\n",
        "            'original_category': sentiment_result['category'],\n",
        "            'adjusted_category': sentiment_result['category'],\n",
        "            'was_adjusted': False\n",
        "        }\n",
        "\n",
        "def calculate_game_scores(df):\n",
        "    print(\"Performing sentiment analysis...\")\n",
        "\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    results = []\n",
        "    game_stats = defaultdict(lambda: {\n",
        "        'title': '',\n",
        "        'reviews': [],\n",
        "        'sentiment_scores': [],\n",
        "        'adjusted_scores': [],\n",
        "        'categories': [],\n",
        "        'adjusted_categories': [],\n",
        "        'adjustment_count': 0\n",
        "    })\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Sentiment Analysis Progress\"):\n",
        "        app_id = row['app_id']\n",
        "        text = row['review_text']\n",
        "\n",
        "        if game_stats[app_id]['title'] == '':\n",
        "            game_stats[app_id]['title'] = row['title']\n",
        "\n",
        "        sentiment_result = analyze_sentiment_with_vader(text, analyzer)\n",
        "        priority_adjustment = apply_recommendation_priority(row, sentiment_result)\n",
        "\n",
        "        game_stats[app_id]['reviews'].append(text)\n",
        "        game_stats[app_id]['sentiment_scores'].append(sentiment_result['normalized'])\n",
        "        game_stats[app_id]['adjusted_scores'].append(priority_adjustment['adjusted_score'])\n",
        "        game_stats[app_id]['categories'].append(sentiment_result['category'])\n",
        "        game_stats[app_id]['adjusted_categories'].append(priority_adjustment['adjusted_category'])\n",
        "\n",
        "        if priority_adjustment['was_adjusted']:\n",
        "            game_stats[app_id]['adjustment_count'] += 1\n",
        "\n",
        "        results.append({\n",
        "            'app_id': app_id,\n",
        "            'title': row['title'],\n",
        "            'review_text': text[:200] + '...' if len(text) > 200 else text,\n",
        "            'recommendation': row['recommendation'],\n",
        "            'sentiment_label': row['sentiment_label'],\n",
        "            'vader_compound': sentiment_result['compound'],\n",
        "            'original_score': sentiment_result['normalized'],\n",
        "            'adjusted_score': priority_adjustment['adjusted_score'],\n",
        "            'original_category': sentiment_result['category'],\n",
        "            'adjusted_category': priority_adjustment['adjusted_category'],\n",
        "            'was_adjusted': priority_adjustment['was_adjusted']\n",
        "        })\n",
        "\n",
        "    print(f\"Completed sentiment analysis for {len(results)} reviews\")\n",
        "\n",
        "    print(\"Calculating game scores...\")\n",
        "    game_scores = []\n",
        "\n",
        "    for app_id, stats in tqdm(game_stats.items(), desc=\"Game Score Calculation Progress\"):\n",
        "        if len(stats['adjusted_scores']) == 0:\n",
        "            continue\n",
        "\n",
        "        avg_adjusted_score = np.mean(stats['adjusted_scores'])\n",
        "        score_10_point = round(avg_adjusted_score * 10, 1)\n",
        "\n",
        "        category_counts = pd.Series(stats['adjusted_categories']).value_counts()\n",
        "\n",
        "        game_scores.append({\n",
        "            'app_id': app_id,\n",
        "            'title': stats['title'],\n",
        "            'review_count': len(stats['reviews']),\n",
        "            'avg_original_score': round(np.mean(stats['sentiment_scores']) * 10, 1),\n",
        "            'avg_adjusted_score': score_10_point,\n",
        "            'positive_count': category_counts.get('positive', 0),\n",
        "            'negative_count': category_counts.get('negative', 0),\n",
        "            'neutral_count': category_counts.get('neutral', 0),\n",
        "            'adjustment_count': stats['adjustment_count'],\n",
        "            'adjustment_rate': round(stats['adjustment_count'] / len(stats['reviews']) * 100, 1) if len(stats['reviews']) > 0 else 0\n",
        "        })\n",
        "\n",
        "    game_scores_df = pd.DataFrame(game_scores).sort_values('avg_adjusted_score', ascending=False)\n",
        "\n",
        "    return pd.DataFrame(results), game_scores_df\n",
        "\n",
        "def generate_final_output(game_scores_df):\n",
        "    print(\"Generating final output...\")\n",
        "\n",
        "    final_scores = game_scores_df[['app_id', 'avg_adjusted_score']].copy()\n",
        "    final_scores.columns = ['app_id', 'sentiment_score_10point']\n",
        "\n",
        "    final_scores.to_csv('game_sentiment_scores.csv', index=False, encoding='utf-8-sig')\n",
        "    print(f\"Final scores saved to game_sentiment_scores.csv, total {len(final_scores)} games\")\n",
        "\n",
        "    return final_scores\n",
        "\n",
        "def main():\n",
        "    print(\"=== Game Review Sentiment Analysis System ===\")\n",
        "    print(\"Purpose: Generate a 10-point sentiment score for each game using unsupervised sentiment analysis with a recommendation-priority rule.\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    df = load_and_prepare_data()\n",
        "    if df is None:\n",
        "        return\n",
        "\n",
        "    detailed_results, game_scores = calculate_game_scores(df)\n",
        "    final_scores = generate_final_output(game_scores)\n",
        "\n",
        "    detailed_results.to_csv('detailed_sentiment_analysis.csv', index=False, encoding='utf-8-sig')\n",
        "    game_scores.to_csv('game_sentiment_analysis_summary.csv', index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(\"\\n=== Analysis Complete ===\")\n",
        "    print(f\"Number of games analyzed: {len(game_scores)}\")\n",
        "    print(f\"Number of reviews analyzed: {len(detailed_results)}\")\n",
        "\n",
        "    avg_score = game_scores['avg_adjusted_score'].mean()\n",
        "    print(f\"Average game sentiment score: {avg_score:.1f}/10\")\n",
        "\n",
        "    total_adjustments = detailed_results['was_adjusted'].sum()\n",
        "    adjustment_rate = total_adjustments / len(detailed_results) * 100\n",
        "    print(f\"Recommendation-priority rule adjustments: {total_adjustments} ({adjustment_rate:.1f}% of reviews)\")\n",
        "\n",
        "    print(\"\\n=== Top 5 Games by Sentiment Score ===\")\n",
        "    top_5 = game_scores.head()\n",
        "    for _, row in top_5.iterrows():\n",
        "        print(f\"{row['title']} (ID: {row['app_id']}): {row['avg_adjusted_score']}/10\")\n",
        "\n",
        "    print(\"\\n=== Bottom 5 Games by Sentiment Score ===\")\n",
        "    bottom_5 = game_scores.tail()\n",
        "    for _, row in bottom_5.iterrows():\n",
        "        print(f\"{row['title']} (ID: {row['app_id']}): {row['avg_adjusted_score']}/10\")\n",
        "\n",
        "    print(\"\\n=== Generated Files ===\")\n",
        "    print(\"1. game_sentiment_scores.csv - Final game sentiment scores (App ID + 10-point score)\")\n",
        "    print(\"2. detailed_sentiment_analysis.csv - Detailed sentiment analysis for each review\")\n",
        "    print(\"3. game_sentiment_analysis_summary.csv - Detailed sentiment statistics for each game\")\n",
        "\n",
        "    print(\"\\nTip: You can directly use game_sentiment_scores.csv for subsequent analysis\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
