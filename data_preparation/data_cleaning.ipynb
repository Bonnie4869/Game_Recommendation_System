{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHQGz4-gs_DG"
      },
      "source": [
        "dataset preparation for component2/3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EYuOsz2sZOW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def filter_data_by_game_ids():\n",
        "    print(\"Reading game data...\")\n",
        "    ga_data = pd.read_csv('ga.csv')\n",
        "    valid_game_ids = set(ga_data['app_id'])\n",
        "    print(f\"Total {len(valid_game_ids)} valid game IDs\")\n",
        "\n",
        "    print(\"\\nProcessing review data (re.csv)...\")\n",
        "\n",
        "    output_re_file = 're_filtered.csv'\n",
        "    output_us_file = 'us_filtered.csv'\n",
        "\n",
        "    chunk_size = 10000\n",
        "    first_chunk = True\n",
        "\n",
        "    valid_user_ids_from_re = set()\n",
        "\n",
        "    for chunk in pd.read_csv('re.csv', chunksize=chunk_size):\n",
        "        filtered_chunk = chunk[chunk['app_id'].isin(valid_game_ids)]\n",
        "\n",
        "        valid_user_ids_from_re.update(filtered_chunk['user_id'].unique())\n",
        "\n",
        "        if first_chunk:\n",
        "            filtered_chunk.to_csv(output_re_file, index=False, mode='w')\n",
        "            first_chunk = False\n",
        "        else:\n",
        "            filtered_chunk.to_csv(output_re_file, index=False, mode='a', header=False)\n",
        "\n",
        "        print(f\"Processed {len(chunk)} records, kept {len(filtered_chunk)}\")\n",
        "\n",
        "    print(f\"Review data saved to {output_re_file}\")\n",
        "    print(f\"Collected {len(valid_user_ids_from_re)} valid user IDs from review data\")\n",
        "\n",
        "    print(\"\\nProcessing user data (us.csv)...\")\n",
        "\n",
        "    first_chunk = True\n",
        "    total_processed = 0\n",
        "    total_kept = 0\n",
        "\n",
        "    for chunk in pd.read_csv('us.csv', chunksize=chunk_size):\n",
        "        total_processed += len(chunk)\n",
        "\n",
        "        filtered_chunk = chunk[chunk['user_id'].isin(valid_user_ids_from_re)]\n",
        "        total_kept += len(filtered_chunk)\n",
        "\n",
        "        if first_chunk:\n",
        "            filtered_chunk.to_csv(output_us_file, index=False, mode='w')\n",
        "            first_chunk = False\n",
        "        else:\n",
        "            filtered_chunk.to_csv(output_us_file, index=False, mode='a', header=False)\n",
        "\n",
        "        print(f\"Processed {len(chunk)} user records, kept {len(filtered_chunk)}\")\n",
        "\n",
        "    print(f\"\\nUser data saved to {output_us_file}\")\n",
        "    print(f\"Total processed {total_processed} user records, kept {total_kept} ({total_kept/total_processed*100:.1f}%)\")\n",
        "\n",
        "    print(\"\\n=== Data filtering completed ===\")\n",
        "    print(f\"Valid games: {len(valid_game_ids)}\")\n",
        "    print(f\"Valid users: {len(valid_user_ids_from_re)}\")\n",
        "\n",
        "    for file_path in [output_re_file, output_us_file]:\n",
        "        if os.path.exists(file_path):\n",
        "            file_size = os.path.getsize(file_path) / (1024*1024)\n",
        "            print(f\"{file_path}: {file_size:.2f} MB\")\n",
        "\n",
        "def filter_data_by_game_ids_memory_optimized():\n",
        "    import csv\n",
        "\n",
        "    print(\"Reading game data...\")\n",
        "    ga_data = pd.read_csv('ga.csv')\n",
        "    valid_game_ids = set(ga_data['app_id'])\n",
        "    print(f\"Total {len(valid_game_ids)} valid game IDs\")\n",
        "\n",
        "    print(\"\\nProcessing review data (re.csv)...\")\n",
        "    re_output_file = 're_filtered.csv'\n",
        "\n",
        "    valid_user_ids = set()\n",
        "    re_count = 0\n",
        "    kept_re_count = 0\n",
        "\n",
        "    with open('re.csv', 'r', encoding='utf-8') as infile, \\\n",
        "         open(re_output_file, 'w', encoding='utf-8', newline='') as outfile:\n",
        "\n",
        "        reader = csv.DictReader(infile)\n",
        "        fieldnames = reader.fieldnames\n",
        "\n",
        "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for row in reader:\n",
        "            re_count += 1\n",
        "            app_id = int(row['app_id']) if row['app_id'].isdigit() else row['app_id']\n",
        "\n",
        "            if app_id in valid_game_ids:\n",
        "                writer.writerow(row)\n",
        "                kept_re_count += 1\n",
        "                valid_user_ids.add(row['user_id'])\n",
        "\n",
        "            if re_count % 10000 == 0:\n",
        "                print(f\"Processed {re_count} reviews, kept {kept_re_count}\")\n",
        "\n",
        "    print(f\"Review data saved to {re_output_file}\")\n",
        "    print(f\"Collected {len(valid_user_ids)} valid user IDs from review data\")\n",
        "\n",
        "    print(\"\\nProcessing user data (us.csv)...\")\n",
        "    us_output_file = 'us_filtered.csv'\n",
        "\n",
        "    us_count = 0\n",
        "    kept_us_count = 0\n",
        "\n",
        "    with open('us.csv', 'r', encoding='utf-8') as infile, \\\n",
        "         open(us_output_file, 'w', encoding='utf-8', newline='') as outfile:\n",
        "\n",
        "        reader = csv.DictReader(infile)\n",
        "        fieldnames = reader.fieldnames\n",
        "\n",
        "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for row in reader:\n",
        "            us_count += 1\n",
        "            user_id = row['user_id']\n",
        "\n",
        "            if user_id in valid_user_ids:\n",
        "                writer.writerow(row)\n",
        "                kept_us_count += 1\n",
        "\n",
        "            if us_count % 10000 == 0:\n",
        "                print(f\"Processed {us_count} user records, kept {kept_us_count}\")\n",
        "\n",
        "    print(f\"User data saved to {us_output_file}\")\n",
        "\n",
        "    print(\"\\n=== Data filtering completed ===\")\n",
        "    print(f\"Valid games: {len(valid_game_ids)}\")\n",
        "    print(f\"Valid users: {len(valid_user_ids)}\")\n",
        "    print(f\"Reviews: {re_count} -> {kept_re_count} ({kept_re_count/re_count*100:.1f}%)\")\n",
        "    print(f\"Users: {us_count} -> {kept_us_count} ({kept_us_count/us_count*100:.1f}%)\")\n",
        "\n",
        "def split_by_game_id():\n",
        "    print(\"Splitting review data by game ID...\")\n",
        "\n",
        "    ga_data = pd.read_csv('ga.csv')\n",
        "    valid_game_ids = set(ga_data['app_id'])\n",
        "\n",
        "    output_files = {}\n",
        "\n",
        "    with open('re.csv', 'r', encoding='utf-8') as f:\n",
        "        header = f.readline()\n",
        "\n",
        "    chunk_size = 50000\n",
        "    for chunk in pd.read_csv('re.csv', chunksize=chunk_size):\n",
        "        filtered_chunk = chunk[chunk['app_id'].isin(valid_game_ids)]\n",
        "\n",
        "        for game_id, group in filtered_chunk.groupby('app_id'):\n",
        "            if game_id not in output_files:\n",
        "                filename = f're_game_{game_id}.csv'\n",
        "                output_files[game_id] = open(filename, 'w', encoding='utf-8')\n",
        "                output_files[game_id].write(header)\n",
        "\n",
        "            group.to_csv(output_files[game_id], index=False, header=False, mode='a')\n",
        "\n",
        "    for f in output_files.values():\n",
        "        f.close()\n",
        "\n",
        "    print(f\"Created {len(output_files)} files split by game ID\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Please choose processing method:\")\n",
        "    print(\"1. Standard chunked processing (for large files)\")\n",
        "    print(\"2. Memory-optimized line-by-line processing (for very large files)\")\n",
        "    print(\"3. Split and save by game ID\")\n",
        "\n",
        "    choice = input(\"Enter option (1-3): \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        filter_data_by_game_ids()\n",
        "    elif choice == \"2\":\n",
        "        filter_data_by_game_ids_memory_optimized()\n",
        "    elif choice == \"3\":\n",
        "        split_by_game_id()\n",
        "    else:\n",
        "        print(\"Using default standard chunked processing...\")\n",
        "        filter_data_by_game_ids()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu1m59DUtUyc"
      },
      "source": [
        "useful game data filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7J4GFQGVsyo8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def analyze_game_reviews(file_path, min_reviews=15):\n",
        "    print(f\"Starting to process file: {file_path}\")\n",
        "    print(f\"File size: {Path(file_path).stat().st_size / (1024*1024):.2f} MB\")\n",
        "\n",
        "    def process_in_chunks():\n",
        "        print(\"Processing large file using chunked reading...\")\n",
        "\n",
        "        stats = {}\n",
        "        chunksize = 100000\n",
        "        total_chunks = 0\n",
        "\n",
        "        try:\n",
        "            print(\"Calculating total number of rows in the file...\")\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                total_rows = sum(1 for _ in f) - 1\n",
        "            print(f\"Total rows: {total_rows:,}\")\n",
        "\n",
        "            chunk_iter = pd.read_csv(file_path,\n",
        "                                     chunksize=chunksize,\n",
        "                                     encoding='utf-8',\n",
        "                                     on_bad_lines='warn',\n",
        "                                     low_memory=False)\n",
        "\n",
        "            with tqdm(total=total_rows, desc=\"Processing Progress\") as pbar:\n",
        "                for chunk in chunk_iter:\n",
        "                    total_chunks += 1\n",
        "\n",
        "                    chunk.columns = chunk.columns.str.strip()\n",
        "\n",
        "                    required_cols = ['app_id', 'recommendation']\n",
        "                    missing_cols = [col for col in required_cols if col not in chunk.columns]\n",
        "                    if missing_cols:\n",
        "                        print(f\"Warning: Missing required columns: {missing_cols}\")\n",
        "                        print(f\"Available columns: {list(chunk.columns)}\")\n",
        "                        continue\n",
        "\n",
        "                    for _, row in chunk.iterrows():\n",
        "                        app_id = str(row['app_id']).strip()\n",
        "\n",
        "                        if app_id not in stats:\n",
        "                            stats[app_id] = {\n",
        "                                'total_reviews': 0,\n",
        "                                'recommended': 0,\n",
        "                                'not_recommended': 0\n",
        "                            }\n",
        "\n",
        "                        stats[app_id]['total_reviews'] += 1\n",
        "\n",
        "                        rec = str(row['recommendation']).strip().lower()\n",
        "                        if rec == 'recommended':\n",
        "                            stats[app_id]['recommended'] += 1\n",
        "                        elif rec == 'not recommended':\n",
        "                            stats[app_id]['not_recommended'] += 1\n",
        "\n",
        "                    pbar.update(len(chunk))\n",
        "\n",
        "            print(f\"Processing complete, read {total_chunks} chunks\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: File '{file_path}' does not exist\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {e}\")\n",
        "            return None\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def process_directly():\n",
        "        print(\"Processing file using direct reading...\")\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, encoding='utf-8', on_bad_lines='warn', low_memory=False)\n",
        "\n",
        "            df.columns = df.columns.str.strip()\n",
        "\n",
        "            required_cols = ['app_id', 'recommendation']\n",
        "            for col in required_cols:\n",
        "                if col not in df.columns:\n",
        "                    print(f\"Error: Missing required column '{col}'\")\n",
        "                    print(f\"Available columns: {list(df.columns)}\")\n",
        "                    return None\n",
        "\n",
        "            df['app_id'] = df['app_id'].astype(str).str.strip()\n",
        "            df['recommendation'] = df['recommendation'].astype(str).str.strip().str.lower()\n",
        "\n",
        "            stats = {}\n",
        "            for app_id, group in df.groupby('app_id'):\n",
        "                total = len(group)\n",
        "                recommended = (group['recommendation'] == 'recommended').sum()\n",
        "                not_recommended = (group['recommendation'] == 'not recommended').sum()\n",
        "\n",
        "                stats[app_id] = {\n",
        "                    'total_reviews': total,\n",
        "                    'recommended': recommended,\n",
        "                    'not_recommended': not_recommended\n",
        "                }\n",
        "\n",
        "            return stats\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {e}\")\n",
        "            return None\n",
        "\n",
        "    file_size_mb = Path(file_path).stat().st_size / (1024*1024)\n",
        "\n",
        "    if file_size_mb > 50:\n",
        "        stats = process_in_chunks()\n",
        "    else:\n",
        "        stats = process_directly()\n",
        "\n",
        "    if stats is None:\n",
        "        print(\"Statistics failed\")\n",
        "        return None\n",
        "\n",
        "    results = []\n",
        "    for app_id, data in stats.items():\n",
        "        total = data['total_reviews']\n",
        "        recommended = data['recommended']\n",
        "        not_recommended = data['not_recommended']\n",
        "        neutral = total - recommended - not_recommended\n",
        "\n",
        "        results.append({\n",
        "            'app_id': app_id,\n",
        "            'total_reviews': total,\n",
        "            'recommended': recommended,\n",
        "            'not_recommended': not_recommended,\n",
        "            'neutral': neutral,\n",
        "            'recommendation_rate': recommended / total if total > 0 else 0,\n",
        "            'not_recommendation_rate': not_recommended / total if total > 0 else 0,\n",
        "            'neutral_rate': neutral / total if total > 0 else 0\n",
        "        })\n",
        "\n",
        "    df_results = pd.DataFrame(results)\n",
        "    df_filtered = df_results[df_results['total_reviews'] >= min_reviews].copy()\n",
        "    filtered_out = df_results[df_results['total_reviews'] < min_reviews]\n",
        "    df_filtered = df_filtered.sort_values('total_reviews', ascending=False)\n",
        "\n",
        "    return df_filtered, filtered_out\n",
        "\n",
        "def save_results(df_filtered, filtered_out, output_dir='results'):\n",
        "    Path(output_dir).mkdir(exist_ok=True)\n",
        "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    main_file = f\"{output_dir}/game_review_stats_{timestamp}.csv\"\n",
        "    df_filtered.to_csv(main_file, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    if not filtered_out.empty:\n",
        "        filtered_file = f\"{output_dir}/filtered_games_{timestamp}.csv\"\n",
        "        filtered_out.to_csv(filtered_file, index=False, encoding='utf-8-sig')\n",
        "        print(f\"Filtered-out games saved to: {filtered_file}\")\n",
        "\n",
        "    total_reviews = df_filtered['total_reviews'].sum()\n",
        "    total_recommended = df_filtered['recommended'].sum()\n",
        "    total_not_recommended = df_filtered['not_recommended'].sum()\n",
        "    total_neutral = df_filtered['neutral'].sum()\n",
        "\n",
        "    summary = {\n",
        "        'Analysis Time': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        'Total Games Analyzed': len(df_filtered),\n",
        "        'Games Filtered Out': len(filtered_out),\n",
        "        'Total Reviews': total_reviews,\n",
        "        'Total Recommended': total_recommended,\n",
        "        'Total Not Recommended': total_not_recommended,\n",
        "        'Total N/A Reviews': total_neutral,\n",
        "        'Overall Recommendation Rate': f\"{total_recommended/total_reviews*100:.1f}%\",\n",
        "        'Overall Not Recommendation Rate': f\"{total_not_recommended/total_reviews*100:.1f}%\",\n",
        "        'Overall N/A Rate': f\"{total_neutral/total_reviews*100:.1f}%\",\n",
        "        'Average Recommendation Rate': f\"{df_filtered['recommendation_rate'].mean()*100:.1f}%\",\n",
        "        'Average Not Recommendation Rate': f\"{df_filtered['not_recommendation_rate'].mean()*100:.1f}%\",\n",
        "        'Game with Highest Recommendation Rate': df_filtered.loc[df_filtered['recommendation_rate'].idxmax(), 'app_id'],\n",
        "        'Highest Recommendation Rate': f\"{df_filtered['recommendation_rate'].max()*100:.1f}%\",\n",
        "        'Game with Highest Not Recommendation Rate': df_filtered.loc[df_filtered['not_recommendation_rate'].idxmax(), 'app_id'],\n",
        "        'Highest Not Recommendation Rate': f\"{df_filtered['not_recommendation_rate'].max()*100:.1f}%\",\n",
        "        'Most Reviewed Game': df_filtered.loc[df_filtered['total_reviews'].idxmax(), 'app_id'],\n",
        "        'Most Reviews': df_filtered['total_reviews'].max()\n",
        "    }\n",
        "\n",
        "    summary_file = f\"{output_dir}/summary_{timestamp}.txt\"\n",
        "    with open(summary_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"Game Review Statistics Analysis Summary\\n\")\n",
        "        f.write(\"=\" * 60 + \"\\n\")\n",
        "        for key, value in summary.items():\n",
        "            f.write(f\"{key:25}: {value}\\n\")\n",
        "\n",
        "    report_file = f\"{output_dir}/detailed_report_{timestamp}.txt\"\n",
        "    with open(report_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"Detailed Game Review Statistics Analysis Report\\n\")\n",
        "        f.write(\"=\" * 100 + \"\\n\\n\")\n",
        "\n",
        "        f.write(\"【Overall Statistics】\\n\")\n",
        "        f.write(\"-\" * 60 + \"\\n\")\n",
        "        f.write(f\"Analyzed Games: {len(df_filtered):,}\\n\")\n",
        "        f.write(f\"Total Reviews: {total_reviews:,}\\n\")\n",
        "        f.write(f\"Recommended: {total_recommended:,} ({total_recommended/total_reviews*100:.1f}%)\\n\")\n",
        "        f.write(f\"Not Recommended: {total_not_recommended:,} ({total_not_recommended/total_reviews*100:.1f}%)\\n\")\n",
        "        f.write(f\"N/A: {total_neutral:,} ({total_neutral/total_reviews*100:.1f}%)\\n\\n\")\n",
        "\n",
        "        f.write(\"【Top 10 Games by Recommendation Rate】\\n\")\n",
        "        f.write(\"-\" * 100 + \"\\n\")\n",
        "        f.write(f\"{'Rank':<4} {'Game ID':<15} {'Reviews':<10} {'Rec.':<10} {'Not Rec.':<12} {'Rec. Rate':<10} {'Not Rec. Rate':<10}\\n\")\n",
        "        f.write(\"-\" * 100 + \"\\n\")\n",
        "\n",
        "        top_recommended = df_filtered.nlargest(10, 'recommendation_rate')\n",
        "        for i, (_, row) in enumerate(top_recommended.iterrows(), 1):\n",
        "            f.write(f\"{i:<4} {row['app_id']:<15} {row['total_reviews']:<10} {row['recommended']:<10} \"\n",
        "                    f\"{row['not_recommended']:<12} {row['recommendation_rate']*100:>9.1f}% {row['not_recommendation_rate']*100:>9.1f}%\\n\")\n",
        "\n",
        "        f.write(\"\\n【Top 10 Games by Not Recommendation Rate】\\n\")\n",
        "        f.write(\"-\" * 100 + \"\\n\")\n",
        "        f.write(f\"{'Rank':<4} {'Game ID':<15} {'Reviews':<10} {'Rec.':<10} {'Not Rec.':<12} {'Rec. Rate':<10} {'Not Rec. Rate':<10}\\n\")\n",
        "        f.write(\"-\" * 100 + \"\\n\")\n",
        "\n",
        "        top_not_recommended = df_filtered.nlargest(10, 'not_recommendation_rate')\n",
        "        for i, (_, row) in enumerate(top_not_recommended.iterrows(), 1):\n",
        "            f.write(f\"{i:<4} {row['app_id']:<15} {row['total_reviews']:<10} {row['recommended']:<10} \"\n",
        "                    f\"{row['not_recommended']:<12} {row['recommendation_rate']*100:>9.1f}% {row['not_recommendation_rate']*100:>9.1f}%\\n\")\n",
        "\n",
        "        f.write(\"\\n【Top 10 Most Reviewed Games】\\n\")\n",
        "        f.write(\"-\" * 100 + \"\\n\")\n",
        "        f.write(f\"{'Rank':<4} {'Game ID':<15} {'Reviews':<10} {'Rec.':<10} {'Not Rec.':<12} {'Rec. Rate':<10} {'Not Rec. Rate':<10}\\n\")\n",
        "        f.write(\"-\" * 100 + \"\\n\")\n",
        "\n",
        "        top_reviewed = df_filtered.nlargest(10, 'total_reviews')\n",
        "        for i, (_, row) in enumerate(top_reviewed.iterrows(), 1):\n",
        "            f.write(f\"{i:<4} {row['app_id']:<15} {row['total_reviews']:<10} {row['recommended']:<10} \"\n",
        "                    f\"{row['not_recommended']:<12} {row['recommendation_rate']*100:>9.1f}% {row['not_recommendation_rate']*100:>9.1f}%\\n\")\n",
        "\n",
        "    print(f\"Main results saved to: {main_file}\")\n",
        "    print(f\"Summary saved to: {summary_file}\")\n",
        "    print(f\"Detailed report saved to: {report_file}\")\n",
        "\n",
        "    return main_file\n",
        "\n",
        "def print_summary(df_filtered):\n",
        "    if df_filtered is None or df_filtered.empty:\n",
        "        print(\"No results to display\")\n",
        "        return\n",
        "\n",
        "    total_reviews = df_filtered['total_reviews'].sum()\n",
        "    total_recommended = df_filtered['recommended'].sum()\n",
        "    total_not_recommended = df_filtered['not_recommended'].sum()\n",
        "    total_neutral = df_filtered['neutral'].sum()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Game Review Statistics Results\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Games meeting criteria: {len(df_filtered):,}\")\n",
        "    print(f\"Total reviews: {total_reviews:,}\")\n",
        "    print(f\"Recommended: {total_recommended:,} ({total_recommended/total_reviews*100:.1f}%)\")\n",
        "    print(f\"Not Recommended: {total_not_recommended:,} ({total_not_recommended/total_reviews*100:.1f}%)\")\n",
        "    print(f\"N/A: {total_neutral:,} ({total_neutral/total_reviews*100:.1f}%)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(\"\\nStatistics for the top 20 games:\")\n",
        "    print(\"-\"*100)\n",
        "    print(f\"{'Game ID':<12} {'Reviews':<10} {'Rec.':<8} {'Not Rec.':<8} {'N/A':<8} {'Rec. Rate':<10} {'Not Rec. Rate':<10}\")\n",
        "    print(\"-\"*100)\n",
        "\n",
        "    for _, row in df_filtered.head(20).iterrows():\n",
        "        rec_rate = row['recommendation_rate'] * 100\n",
        "        not_rec_rate = row['not_recommendation_rate'] * 100\n",
        "        print(f\"{row['app_id']:<12} {row['total_reviews']:<10,} {row['recommended']:<8} \"\n",
        "              f\"{row['not_recommended']:<8} {row['neutral']:<8} {rec_rate:>8.1f}% {not_rec_rate:>9.1f}%\")\n",
        "\n",
        "    if len(df_filtered) > 20:\n",
        "        print(f\"... {len(df_filtered) - 20} more games not shown\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = \"game_review.csv\"\n",
        "\n",
        "    if not Path(input_file).exists():\n",
        "        print(f\"Error: File '{input_file}' does not exist\")\n",
        "        print(\"Please ensure the file path is correct\")\n",
        "        exit(1)\n",
        "\n",
        "    MIN_REVIEWS = 15\n",
        "\n",
        "    try:\n",
        "        print(\"Starting analysis of game review data...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        df_filtered, filtered_out = analyze_game_reviews(input_file, min_reviews=MIN_REVIEWS)\n",
        "\n",
        "        if df_filtered is not None and not df_filtered.empty:\n",
        "            print_summary(df_filtered)\n",
        "            output_file = save_results(df_filtered, filtered_out)\n",
        "\n",
        "            end_time = time.time()\n",
        "            print(f\"\\nAnalysis complete! Time elapsed: {end_time - start_time:.2f} seconds\")\n",
        "            print(f\"Results saved to '{output_file}'\")\n",
        "\n",
        "            print(\"\\nKey statistics:\")\n",
        "            print(f\"- Most reviewed game: {df_filtered.iloc[0]['app_id']} ({df_filtered.iloc[0]['total_reviews']:,} reviews)\")\n",
        "            print(f\"- Game with highest recommendation rate: {df_filtered.loc[df_filtered['recommendation_rate'].idxmax()]['app_id']} ({df_filtered['recommendation_rate'].max()*100:.1f}%)\")\n",
        "            print(f\"- Game with highest not recommendation rate: {df_filtered.loc[df_filtered['not_recommendation_rate'].idxmax()]['app_id']} ({df_filtered['not_recommendation_rate'].max()*100:.1f}%)\")\n",
        "\n",
        "            print(\"\\nReview type distribution:\")\n",
        "            print(f\" Recommended: {total_recommended:,} ({total_recommended/total_reviews*100:.1f}%)\")\n",
        "            print(f\" Not Recommended: {total_not_recommended:,} ({total_not_recommended/total_reviews*100:.1f}%)\")\n",
        "            print(f\" N/A: {total_neutral:,} ({total_neutral/total_reviews*100:.1f}%)\")\n",
        "        else:\n",
        "            print(\"No qualifying game data found\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nProcess interrupted by user\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during execution: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
